{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce23dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from txai.models.encoders.transformer_simple import TransformerMVTS\n",
    "from txai.utils.predictors.eval import eval_mv4\n",
    "from txai.synth_data.simple_spike import SpikeTrainDataset\n",
    "from txai.utils.data import process_Synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b457a56",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/n/data1/hms/dbmi/zitnik/lab/users/owq978/TimeSeriesCBM/datasets/FreqShapesUD/split=1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m D \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_Synth\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_no\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/n/data1/hms/dbmi/zitnik/lab/users/owq978/TimeSeriesCBM/datasets/FreqShapesUD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m TransformerMVTS(\n\u001b[1;32m      4\u001b[0m     d_inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m     max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# norm_embedding = True\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/transformer_split=1_cpu.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/n/data1/hms/dbmi/zitnik/lab/users/owq978/TimeSeriesCBM/txai/utils/data/synth.py:12\u001b[0m, in \u001b[0;36mprocess_Synth\u001b[0;34m(split_no, device, base_path, regression, label_noise)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_Synth\u001b[39m(split_no \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, base_path \u001b[38;5;241m=\u001b[39m spike_path, regression \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m         label_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     10\u001b[0m     split_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(split_no))\n\u001b[0;32m---> 12\u001b[0m     D \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     D[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loader\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mX \u001b[38;5;241m=\u001b[39m D[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loader\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m     D[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loader\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtimes \u001b[38;5;241m=\u001b[39m D[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loader\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtimes\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/tXAI/lib/python3.8/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/tXAI/lib/python3.8/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/tXAI/lib/python3.8/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/n/data1/hms/dbmi/zitnik/lab/users/owq978/TimeSeriesCBM/datasets/FreqShapesUD/split=1.pt'"
     ]
    }
   ],
   "source": [
    "D = process_Synth(split_no = 1, device = None, base_path = '/n/data1/hms/dbmi/zitnik/lab/users/owq978/TimeSeriesCBM/datasets/FreqShapesUD')\n",
    "\n",
    "model = TransformerMVTS(\n",
    "    d_inp = 1,\n",
    "    max_len = 50,\n",
    "    n_classes = 4,\n",
    "    trans_dim_feedforward = 16,\n",
    "    trans_dropout = 0.1,\n",
    "    d_pe = 16,\n",
    "    # aggreg = 'mean',\n",
    "    # norm_embedding = True\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('../models/transformer_split=1_cpu.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d13b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, times, y = D['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434aea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from txai.utils.predictors import eval_mvts_transformer\n",
    "\n",
    "out = model.embed(X, times, captum_input = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ee5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance:\n",
    "f1 = eval_mvts_transformer(D['test'], model)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_exp = D['gt_exps'].float()\n",
    "print(gt_exp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99abf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from txai.utils.functional import transform_to_attn_mask\n",
    "\n",
    "attn_masks = transform_to_attn_mask(gt_exp.squeeze(-1).transpose(0,1))\n",
    "print(attn_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out_masked = model.embed(X, times, captum_input = False, attn_mask = attn_masks)\n",
    "print(out_masked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de576d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "sim = F.cosine_similarity(out, out_masked)\n",
    "print(sim.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(sim.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba94e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_np = sim.detach().numpy()\n",
    "ynp = y.detach().numpy()\n",
    "for yi in y.unique().detach().numpy():\n",
    "    plt.hist(sim_np[ynp == yi], alpha = 0.5, label = '{}'.format(yi))\n",
    "plt.legend()\n",
    "plt.title('Embedding Sim. of Samples in SeqCombSingle (by class)')\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18707867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a test - are embeddings of ground-truth masks of samples closer than some other samples?\n",
    "# Create sim. matrix, ordered by classes:\n",
    "# import torch.nn.functional as F\n",
    "# out_norm = F.normalize(out, dim = -1)\n",
    "# out_masked_norm = F.normalize(out_masked, dim = -1)\n",
    "\n",
    "# #outer = torch.bmm(out_norm.unsqueeze(-1), out_masked_norm.unsqueeze(1))\n",
    "# print(outer.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions of each:\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(X, times)\n",
    "    pred_masked = model(X, times, attn_mask = attn_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11866fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pred_masked_np = pred_masked.argmax(dim=-1).detach().numpy()\n",
    "\n",
    "f1 = f1_score(y[y != 0], pred_masked_np[y!=0], average = 'macro')\n",
    "print('f1 w/o class 0: {:.4f}'.format(f1))\n",
    "\n",
    "for yi in y.unique().detach().numpy():\n",
    "    acc = (pred_masked_np[ynp == yi] == yi).sum() / (ynp == yi).sum()\n",
    "    print('Acc. {} = {:.4f}'.format(yi, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "out_tsne = TSNE().fit_transform(out.detach().numpy())\n",
    "plt.scatter(out_tsne[:,0], out_tsne[:,1], c = ynp, alpha = 0.5)\n",
    "plt.title('Regular Embeddings - SeqCombSingle')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Ground-truth Label')\n",
    "plt.xlabel('TSNE-1')\n",
    "plt.ylabel('TSNE-2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mask_tsne = TSNE().fit_transform(out_masked.detach().numpy())\n",
    "plt.scatter(out_mask_tsne[:,0], out_mask_tsne[:,1], c = ynp, alpha = 0.5)\n",
    "plt.title('Masked Embeddings - SeqCombSingle')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Ground-truth Label')\n",
    "plt.xlabel('TSNE-1')\n",
    "plt.ylabel('TSNE-2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7cc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
